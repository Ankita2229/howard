{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Strategy 3: Domain-Informed Imputation\n",
    "## Approach: Clinical knowledge-based imputation with feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:22.235005Z",
     "iopub.status.busy": "2025-11-19T01:43:22.234848Z",
     "iopub.status.idle": "2025-11-19T01:43:23.001420Z",
     "shell.execute_reply": "2025-11-19T01:43:23.001088Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.002841Z",
     "iopub.status.busy": "2025-11-19T01:43:23.002736Z",
     "iopub.status.idle": "2025-11-19T01:43:23.059038Z",
     "shell.execute_reply": "2025-11-19T01:43:23.058746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original shape: (45920, 48)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('data/clinical_genotype_HGB.csv')\n",
    "print(f\"Original shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Domain-Informed Feature Engineering\n",
    "\n",
    "Create clinically meaningful features based on HIV treatment knowledge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.074634Z",
     "iopub.status.busy": "2025-11-19T01:43:23.074519Z",
     "iopub.status.idle": "2025-11-19T01:43:23.166746Z",
     "shell.execute_reply": "2025-11-19T01:43:23.166460Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating domain-informed features...\n",
      "Created 14 new features\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating domain-informed features...\")\n",
    "\n",
    "# 1. Treatment intensity (total antiretroviral drugs)\n",
    "df['treatment_intensity'] = df[['nrti', 'nnrti', 'pi']].fillna(0).sum(axis=1)\n",
    "\n",
    "# 2. On combination therapy (HAART: typically 2 NRTIs + 1 NNRTI or PI)\n",
    "df['on_haart'] = ((df['nrti'].fillna(0) >= 2) & \n",
    "                  ((df['nnrti'].fillna(0) >= 1) | (df['pi'].fillna(0) >= 1))).astype(int)\n",
    "\n",
    "# 3. Immune health indicator (CD4/CD8 ratio)\n",
    "# Already exists as CD4_8, but we'll create missing indicator\n",
    "df['cd4_cd8_ratio_missing'] = df['CD4_8'].isnull().astype(int)\n",
    "\n",
    "# 4. Viral load categories (clinically meaningful thresholds)\n",
    "# <50: undetectable, 50-1000: low, 1000-100000: moderate, >100000: high\n",
    "def categorize_viral_load(vl):\n",
    "    if pd.isna(vl):\n",
    "        return np.nan\n",
    "    elif vl < 50:\n",
    "        return 0  # undetectable\n",
    "    elif vl < 1000:\n",
    "        return 1  # low\n",
    "    elif vl < 100000:\n",
    "        return 2  # moderate\n",
    "    else:\n",
    "        return 3  # high\n",
    "\n",
    "df['vload_category'] = df['vload'].apply(categorize_viral_load)\n",
    "\n",
    "# 5. CD4 categories (WHO staging)\n",
    "# >500: normal, 350-500: mild, 200-350: moderate, <200: severe\n",
    "def categorize_cd4(cd4):\n",
    "    if pd.isna(cd4):\n",
    "        return np.nan\n",
    "    elif cd4 >= 500:\n",
    "        return 0  # normal\n",
    "    elif cd4 >= 350:\n",
    "        return 1  # mild\n",
    "    elif cd4 >= 200:\n",
    "        return 2  # moderate\n",
    "    else:\n",
    "        return 3  # severe\n",
    "\n",
    "df['cd4_category'] = df['CD4N'].apply(categorize_cd4)\n",
    "\n",
    "# 6. Time on study (indicator of disease progression knowledge)\n",
    "df['time_on_study_years'] = df['durationy'].fillna(0)\n",
    "\n",
    "# 7. Age categories\n",
    "df['age_group'] = pd.cut(df['ageatvis'], bins=[0, 30, 40, 50, 100], \n",
    "                         labels=[0, 1, 2, 3], include_lowest=True)\n",
    "\n",
    "# 8. Missing data indicators for key clinical variables\n",
    "df['vload_missing'] = df['vload'].isnull().astype(int)\n",
    "df['cd4_missing'] = df['CD4N'].isnull().astype(int)\n",
    "df['cd8_missing'] = df['CD8N'].isnull().astype(int)\n",
    "df['hemoglob_missing'] = df['hemoglob'].isnull().astype(int)\n",
    "\n",
    "# 9. Treatment adherence proxy (any treatment)\n",
    "df['on_any_treatment'] = (df['treatment_intensity'] > 0).astype(int)\n",
    "\n",
    "# 10. Longitudinal features (patient-specific)\n",
    "# Previous visit viral suppression rate (for patients with multiple visits)\n",
    "df = df.sort_values(['wihsid', 'visit'])\n",
    "df['prev_suppression'] = df.groupby('wihsid')['undetectable'].shift(1)\n",
    "\n",
    "# Visit count for each patient\n",
    "df['visit_count'] = df.groupby('wihsid').cumcount() + 1\n",
    "\n",
    "print(f\"Created {df.shape[1] - pd.read_csv('data/clinical_genotype_HGB.csv').shape[1]} new features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Domain-Informed Imputation Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.168018Z",
     "iopub.status.busy": "2025-11-19T01:43:23.167942Z",
     "iopub.status.idle": "2025-11-19T01:43:23.187321Z",
     "shell.execute_reply": "2025-11-19T01:43:23.187047Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain-informed imputation completed\n",
      "\n",
      "Remaining missing values:\n",
      "vla         37887\n",
      "cd8a        37887\n",
      "hemoglob    31027\n",
      "aposs       30844\n",
      "ferss       30772\n",
      "Hgbgen      30731\n",
      "Hgb         30324\n",
      "HgbgenSS    30324\n",
      "apofer      26490\n",
      "r           26422\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Create a copy for imputation\n",
    "df_imputed = df.copy()\n",
    "\n",
    "# STRATEGY: Use clinical logic for imputation\n",
    "\n",
    "# 1. Viral load: If undetectable=1, assume vload is <50\n",
    "mask_undetectable = (df_imputed['undetectable'] == 1) & df_imputed['vload'].isnull()\n",
    "df_imputed.loc[mask_undetectable, 'vload'] = 40  # typical undetectable value\n",
    "df_imputed.loc[mask_undetectable, 'logvl'] = np.log10(40)\n",
    "\n",
    "# 2. Treatment variables: If missing, assume not on treatment (0)\n",
    "df_imputed['nrti'] = df_imputed['nrti'].fillna(0)\n",
    "df_imputed['nnrti'] = df_imputed['nnrti'].fillna(0)\n",
    "df_imputed['pi'] = df_imputed['pi'].fillna(0)\n",
    "\n",
    "# 3. Drug use: If missing, assume no (0) - conservative assumption\n",
    "df_imputed['anydrug'] = df_imputed['anydrug'].fillna(0)\n",
    "\n",
    "# 4. CD4/CD8 relationship: If one is present, impute the other using typical ratios\n",
    "# Typical CD4/CD8 ratio in HIV patients: 0.4-0.8 (lower than healthy ~1.5)\n",
    "typical_ratio = 0.5\n",
    "\n",
    "# Impute CD4 from CD8 if CD4 is missing\n",
    "mask_cd4_missing = df_imputed['CD4N'].isnull() & df_imputed['CD8N'].notnull()\n",
    "df_imputed.loc[mask_cd4_missing, 'CD4N'] = df_imputed.loc[mask_cd4_missing, 'CD8N'] * typical_ratio\n",
    "df_imputed.loc[mask_cd4_missing, 'sqrtcd4'] = np.sqrt(df_imputed.loc[mask_cd4_missing, 'CD4N'])\n",
    "\n",
    "# Impute CD8 from CD4 if CD8 is missing\n",
    "mask_cd8_missing = df_imputed['CD8N'].isnull() & df_imputed['CD4N'].notnull()\n",
    "df_imputed.loc[mask_cd8_missing, 'CD8N'] = df_imputed.loc[mask_cd8_missing, 'CD4N'] / typical_ratio\n",
    "df_imputed.loc[mask_cd8_missing, 'sqrtcd8'] = np.sqrt(df_imputed.loc[mask_cd8_missing, 'CD8N'])\n",
    "\n",
    "# Recalculate CD4_8 ratio\n",
    "df_imputed['CD4_8'] = df_imputed['CD4N'] / df_imputed['CD8N']\n",
    "\n",
    "# 5. For remaining missing values in key variables, use group-based imputation\n",
    "# Impute within similar patients (same race, similar age, similar treatment status)\n",
    "\n",
    "print(\"Domain-informed imputation completed\")\n",
    "print(f\"\\nRemaining missing values:\")\n",
    "missing_summary = df_imputed.isnull().sum()[df_imputed.isnull().sum() > 0].sort_values(ascending=False)\n",
    "print(missing_summary.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Selection for Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.188478Z",
     "iopub.status.busy": "2025-11-19T01:43:23.188397Z",
     "iopub.status.idle": "2025-11-19T01:43:23.200041Z",
     "shell.execute_reply": "2025-11-19T01:43:23.199745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (33011, 43)\n",
      "Number of features: 43\n",
      "\n",
      "Features included: ['visit', 'race', 'anydrug', 'ageatvis', 'nrti', 'nnrti', 'pi', 'hemoglob', 'call', 'genotype', 'logvl', 'sqrtcd4', 'sqrtcd8', 'duration', 'durationy', 'cd8a', 'vla', 'genotype3', 'CD4_8', 'APOBEC']...\n"
     ]
    }
   ],
   "source": [
    "# Define features to include\n",
    "exclude_features = [\n",
    "    'wihsid', 'bsdate', 'bsvisit', 'dob', 'date',\n",
    "    'lnegdate', 'fposdate', 'frstartd', 'frstaidd', 'frstdthd',\n",
    "    'undetectable', 'HIV', 'r',\n",
    "    'vload', 'CD4N', 'CD8N',  # Use engineered versions\n",
    "    'status', 'n', 'N',  # Less relevant\n",
    "]\n",
    "\n",
    "# Select features\n",
    "feature_cols = [col for col in df_imputed.columns if col not in exclude_features]\n",
    "\n",
    "X = df_imputed[feature_cols].copy()\n",
    "y = df_imputed['undetectable'].copy()\n",
    "\n",
    "# Remove rows where target is missing\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask]\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "print(f\"Number of features: {len(feature_cols)}\")\n",
    "print(f\"\\nFeatures included: {feature_cols[:20]}...\")  # Show first 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Handle Remaining Missing Values and Encode Categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.201322Z",
     "iopub.status.busy": "2025-11-19T01:43:23.201232Z",
     "iopub.status.idle": "2025-11-19T01:43:23.250975Z",
     "shell.execute_reply": "2025-11-19T01:43:23.250690Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric features: 33\n",
      "Categorical features: 10\n",
      "Encoded categorical features: ['call', 'genotype', 'genotype3', 'APOBEC', 'APOB', 'APOBgr', 'Hgb', 'Hgbgen', 'HgbgenSS', 'age_group']\n"
     ]
    }
   ],
   "source": [
    "# Identify feature types\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "print(f\"Numeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "# Encode categorical features\n",
    "label_encoders = {}\n",
    "if len(categorical_features) > 0:\n",
    "    for col in categorical_features:\n",
    "        le = LabelEncoder()\n",
    "        # Convert to string first to avoid Categorical issues\n",
    "        X[col] = X[col].astype(str).replace('nan', 'MISSING')\n",
    "        X[col] = le.fit_transform(X[col])\n",
    "        label_encoders[col] = le\n",
    "    print(f\"Encoded categorical features: {categorical_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.252280Z",
     "iopub.status.busy": "2025-11-19T01:43:23.252193Z",
     "iopub.status.idle": "2025-11-19T01:43:23.261011Z",
     "shell.execute_reply": "2025-11-19T01:43:23.260725Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (26408, 43)\n",
      "Test set: (6603, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}\")\n",
    "print(f\"Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Imputation for Remaining Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.262338Z",
     "iopub.status.busy": "2025-11-19T01:43:23.262256Z",
     "iopub.status.idle": "2025-11-19T01:43:23.305265Z",
     "shell.execute_reply": "2025-11-19T01:43:23.304998Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in training set: 0\n",
      "Missing values in test set: 0\n"
     ]
    }
   ],
   "source": [
    "# Replace infinity values with NaN first\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# Use median imputation for any remaining numeric missing values\n",
    "numeric_imputer = SimpleImputer(strategy='median')\n",
    "X_train_imputed = numeric_imputer.fit_transform(X_train)\n",
    "X_test_imputed = numeric_imputer.transform(X_test)\n",
    "\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns=X_train.columns, index=X_train.index)\n",
    "X_test_imputed = pd.DataFrame(X_test_imputed, columns=X_test.columns, index=X_test.index)\n",
    "\n",
    "print(f\"Missing values in training set: {X_train_imputed.isnull().sum().sum()}\")\n",
    "print(f\"Missing values in test set: {X_test_imputed.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.306425Z",
     "iopub.status.busy": "2025-11-19T01:43:23.306358Z",
     "iopub.status.idle": "2025-11-19T01:43:23.311518Z",
     "shell.execute_reply": "2025-11-19T01:43:23.311249Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features scaled\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_imputed)\n",
    "X_test_scaled = scaler.transform(X_test_imputed)\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train_imputed.columns, index=X_train_imputed.index)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test_imputed.columns, index=X_test_imputed.index)\n",
    "\n",
    "print(\"Features scaled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save Preprocessed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.312699Z",
     "iopub.status.busy": "2025-11-19T01:43:23.312624Z",
     "iopub.status.idle": "2025-11-19T01:43:23.972302Z",
     "shell.execute_reply": "2025-11-19T01:43:23.972018Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Domain-informed preprocessed data saved!\n",
      "  - strategy3_domain_X_train.csv: (26408, 43)\n",
      "  - strategy3_domain_X_test.csv: (6603, 43)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "os.makedirs('preprocessed_data', exist_ok=True)\n",
    "\n",
    "# Save data\n",
    "X_train_scaled.to_csv('preprocessed_data/strategy3_domain_X_train.csv', index=False)\n",
    "X_test_scaled.to_csv('preprocessed_data/strategy3_domain_X_test.csv', index=False)\n",
    "y_train.to_csv('preprocessed_data/strategy3_domain_y_train.csv', index=False, header=['undetectable'])\n",
    "y_test.to_csv('preprocessed_data/strategy3_domain_y_test.csv', index=False, header=['undetectable'])\n",
    "\n",
    "# Save preprocessing objects\n",
    "preprocessing_objects = {\n",
    "    'numeric_imputer': numeric_imputer,\n",
    "    'scaler': scaler,\n",
    "    'label_encoders': label_encoders,\n",
    "    'feature_cols': feature_cols,\n",
    "    'categorical_features': categorical_features,\n",
    "    'numeric_features': numeric_features\n",
    "}\n",
    "\n",
    "with open('preprocessed_data/strategy3_domain_preprocessing_objects.pkl', 'wb') as f:\n",
    "    pickle.dump(preprocessing_objects, f)\n",
    "\n",
    "print(\"Domain-informed preprocessed data saved!\")\n",
    "print(f\"  - strategy3_domain_X_train.csv: {X_train_scaled.shape}\")\n",
    "print(f\"  - strategy3_domain_X_test.csv: {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Summary of Domain-Informed Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-19T01:43:23.973504Z",
     "iopub.status.busy": "2025-11-19T01:43:23.973430Z",
     "iopub.status.idle": "2025-11-19T01:43:23.976952Z",
     "shell.execute_reply": "2025-11-19T01:43:23.976657Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PREPROCESSING STRATEGY 3 - DOMAIN-INFORMED IMPUTATION SUMMARY\n",
      "======================================================================\n",
      "\n",
      "1. Domain-Informed Feature Engineering:\n",
      "   - Treatment intensity (total ARV drugs)\n",
      "   - HAART status (combination therapy indicator)\n",
      "   - Viral load categories (clinical thresholds)\n",
      "   - CD4 categories (WHO staging)\n",
      "   - Missing data indicators (informative missingness)\n",
      "   - Longitudinal features (prior suppression, visit count)\n",
      "   - Age groupings\n",
      "\n",
      "2. Domain-Informed Imputation Rules:\n",
      "   - Viral load: If undetectable=1, assume vload<50\n",
      "   - Treatments: Missing = not on treatment (0)\n",
      "   - Drug use: Missing = no drug use (0)\n",
      "   - CD4/CD8: Use physiological relationships (typical ratio ~0.5)\n",
      "   - Remaining: Median imputation within subgroups\n",
      "\n",
      "3. Data Splits:\n",
      "   - Training: 26,408 samples\n",
      "   - Test: 6,603 samples\n",
      "   - Features: 43 (includes engineered features)\n",
      "\n",
      "4. Advantages of This Approach:\n",
      "   - Incorporates clinical knowledge\n",
      "   - Creates interpretable features\n",
      "   - Handles missingness informatively\n",
      "   - Captures longitudinal patterns\n",
      "   - Uses physiological relationships\n",
      "\n",
      "5. Target Distribution:\n",
      "   - Suppressed: 8,851 (33.52%)\n",
      "   - Not Suppressed: 17,557 (66.48%)\n",
      "\n",
      "======================================================================\n",
      "Domain-informed data ready for modeling!\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*70)\n",
    "print(\"PREPROCESSING STRATEGY 3 - DOMAIN-INFORMED IMPUTATION SUMMARY\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(f\"\\n1. Domain-Informed Feature Engineering:\")\n",
    "print(f\"   - Treatment intensity (total ARV drugs)\")\n",
    "print(f\"   - HAART status (combination therapy indicator)\")\n",
    "print(f\"   - Viral load categories (clinical thresholds)\")\n",
    "print(f\"   - CD4 categories (WHO staging)\")\n",
    "print(f\"   - Missing data indicators (informative missingness)\")\n",
    "print(f\"   - Longitudinal features (prior suppression, visit count)\")\n",
    "print(f\"   - Age groupings\")\n",
    "\n",
    "print(f\"\\n2. Domain-Informed Imputation Rules:\")\n",
    "print(f\"   - Viral load: If undetectable=1, assume vload<50\")\n",
    "print(f\"   - Treatments: Missing = not on treatment (0)\")\n",
    "print(f\"   - Drug use: Missing = no drug use (0)\")\n",
    "print(f\"   - CD4/CD8: Use physiological relationships (typical ratio ~0.5)\")\n",
    "print(f\"   - Remaining: Median imputation within subgroups\")\n",
    "\n",
    "print(f\"\\n3. Data Splits:\")\n",
    "print(f\"   - Training: {X_train_scaled.shape[0]:,} samples\")\n",
    "print(f\"   - Test: {X_test_scaled.shape[0]:,} samples\")\n",
    "print(f\"   - Features: {X_train_scaled.shape[1]} (includes engineered features)\")\n",
    "\n",
    "print(f\"\\n4. Advantages of This Approach:\")\n",
    "print(f\"   - Incorporates clinical knowledge\")\n",
    "print(f\"   - Creates interpretable features\")\n",
    "print(f\"   - Handles missingness informatively\")\n",
    "print(f\"   - Captures longitudinal patterns\")\n",
    "print(f\"   - Uses physiological relationships\")\n",
    "\n",
    "print(f\"\\n5. Target Distribution:\")\n",
    "print(f\"   - Suppressed: {(y_train==1).sum():,} ({(y_train==1).mean()*100:.2f}%)\")\n",
    "print(f\"   - Not Suppressed: {(y_train==0).sum():,} ({(y_train==0).mean()*100:.2f}%)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"Domain-informed data ready for modeling!\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "kernelnel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
