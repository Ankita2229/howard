{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation and Overfitting Mitigation Techniques\n",
    "\n",
    "## Objectives\n",
    "1. Implement K-fold cross-validation for robust performance estimates\n",
    "2. Apply regularization techniques to prevent overfitting\n",
    "3. Use learning curves to diagnose model behavior\n",
    "4. Implement early stopping for gradient boosting models\n",
    "5. Compare performance across different mitigation strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split, cross_val_score, StratifiedKFold,\n",
    "    learning_curve, validation_curve\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score, make_scorer,\n",
    "    precision_score, recall_score, f1_score\n",
    ")\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data (Corrected Features - No Leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (33011, 27)\n",
      "Class distribution: [21947 11064]\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/clinical_genotype_HGB.csv')\n",
    "\n",
    "# Use corrected features (no data leakage)\n",
    "exclude_features = [\n",
    "    'wihsid', 'bsdate', 'bsvisit', 'dob', 'date',\n",
    "    'lnegdate', 'fposdate', 'frstartd', 'frstaidd', 'frstdthd',\n",
    "    'undetectable', 'HIV', 'r',\n",
    "    'vload', 'logvl', 'vla', 'cd8a',  # Leaking features removed\n",
    "    'status', 'n', 'N', 'visit'\n",
    "]\n",
    "\n",
    "feature_cols = [col for col in df.columns if col not in exclude_features]\n",
    "\n",
    "X = df[feature_cols].copy()\n",
    "y = df['undetectable'].copy()\n",
    "\n",
    "# Remove missing targets\n",
    "mask = y.notna()\n",
    "X = X[mask]\n",
    "y = y[mask].astype(int)\n",
    "\n",
    "print(f\"Dataset shape: {X.shape}\")\n",
    "print(f\"Class distribution: {np.bincount(y)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preprocessed: (33011, 27)\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical features\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "for col in categorical_features:\n",
    "    le = LabelEncoder()\n",
    "    X[col] = le.fit_transform(X[col].astype(str).replace('nan', 'MISSING'))\n",
    "\n",
    "# Impute missing values\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "X_imputed = imputer.fit_transform(X)\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_imputed)\n",
    "\n",
    "print(f\"Data preprocessed: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. K-Fold Cross-Validation\n",
    "\n",
    "Cross-validation provides more robust performance estimates by:\n",
    "- Using all data for both training and validation\n",
    "- Reducing variance in performance estimates\n",
    "- Detecting overfitting through train/validation gaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 5-Fold Stratified Cross-Validation...\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Define cross-validation strategy\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "\n",
    "print(\"Performing 5-Fold Stratified Cross-Validation...\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models with different regularization levels\n",
    "models = {\n",
    "    'Logistic Regression (C=1.0)': LogisticRegression(\n",
    "        C=1.0, max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Logistic Regression (C=0.1)': LogisticRegression(\n",
    "        C=0.1, max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Logistic Regression (C=0.01)': LogisticRegression(\n",
    "        C=0.01, max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Random Forest (depth=None)': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=None, class_weight='balanced', \n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest (depth=10)': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=10, class_weight='balanced',\n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ),\n",
    "    'Random Forest (depth=5)': RandomForestClassifier(\n",
    "        n_estimators=100, max_depth=5, class_weight='balanced',\n",
    "        random_state=RANDOM_STATE, n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost (depth=6)': xgb.XGBClassifier(\n",
    "        n_estimators=100, max_depth=6, learning_rate=0.1,\n",
    "        scale_pos_weight=(y==0).sum()/(y==1).sum(),\n",
    "        random_state=RANDOM_STATE, eval_metric='logloss'\n",
    "    ),\n",
    "    'XGBoost (depth=3)': xgb.XGBClassifier(\n",
    "        n_estimators=100, max_depth=3, learning_rate=0.1,\n",
    "        scale_pos_weight=(y==0).sum()/(y==1).sum(),\n",
    "        random_state=RANDOM_STATE, eval_metric='logloss'\n",
    "    ),\n",
    "    'SVM (C=1.0)': SVC(\n",
    "        C=1.0, kernel='rbf', class_weight='balanced',\n",
    "        probability=True, random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'SVM (C=0.1)': SVC(\n",
    "        C=0.1, kernel='rbf', class_weight='balanced',\n",
    "        probability=True, random_state=RANDOM_STATE\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluating Logistic Regression (C=1.0)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUROC: 0.8368 (+/- 0.0059)\n",
      "\n",
      "Evaluating Logistic Regression (C=0.1)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUROC: 0.8370 (+/- 0.0057)\n",
      "\n",
      "Evaluating Logistic Regression (C=0.01)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: divide by zero encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: overflow encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:200: RuntimeWarning: invalid value encountered in matmul\n",
      "  raw_prediction = X @ weights + intercept\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: divide by zero encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: overflow encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/linear_model/_linear_loss.py:330: RuntimeWarning: invalid value encountered in matmul\n",
      "  grad[:n_features] = X.T @ grad_pointwise + l2_reg_strength * weights\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: divide by zero encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: overflow encountered in matmul\n",
      "  ret = a @ b\n",
      "/Users/ankitarathod/Library/Python/3.9/lib/python/site-packages/sklearn/utils/extmath.py:203: RuntimeWarning: invalid value encountered in matmul\n",
      "  ret = a @ b\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  AUROC: 0.8365 (+/- 0.0052)\n",
      "\n",
      "Evaluating Random Forest (depth=None)...\n",
      "  AUROC: 0.8687 (+/- 0.0043)\n",
      "\n",
      "Evaluating Random Forest (depth=10)...\n",
      "  AUROC: 0.8640 (+/- 0.0048)\n",
      "\n",
      "Evaluating Random Forest (depth=5)...\n",
      "  AUROC: 0.8477 (+/- 0.0064)\n",
      "\n",
      "Evaluating XGBoost (depth=6)...\n",
      "  AUROC: 0.8680 (+/- 0.0061)\n",
      "\n",
      "Evaluating XGBoost (depth=3)...\n",
      "  AUROC: 0.8579 (+/- 0.0072)\n",
      "\n",
      "Evaluating SVM (C=1.0)...\n",
      "  AUROC: 0.8507 (+/- 0.0050)\n",
      "\n",
      "Evaluating SVM (C=0.1)...\n",
      "  AUROC: 0.8472 (+/- 0.0039)\n"
     ]
    }
   ],
   "source": [
    "# Perform cross-validation for each model\n",
    "cv_results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\nEvaluating {name}...\")\n",
    "    \n",
    "    # Cross-validation scores\n",
    "    scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    cv_results.append({\n",
    "        'Model': name,\n",
    "        'Mean AUROC': scores.mean(),\n",
    "        'Std AUROC': scores.std(),\n",
    "        'Min AUROC': scores.min(),\n",
    "        'Max AUROC': scores.max(),\n",
    "        'CV Scores': scores\n",
    "    })\n",
    "    \n",
    "    print(f\"  AUROC: {scores.mean():.4f} (+/- {scores.std()*2:.4f})\")\n",
    "\n",
    "cv_df = pd.DataFrame(cv_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*80)\n",
    "print(cv_df[['Model', 'Mean AUROC', 'Std AUROC', 'Min AUROC', 'Max AUROC']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cross-validation results\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Box plot of CV scores\n",
    "cv_scores_list = [r['CV Scores'] for r in cv_results]\n",
    "model_names = [r['Model'] for r in cv_results]\n",
    "\n",
    "axes[0].boxplot(cv_scores_list, labels=range(len(model_names)))\n",
    "axes[0].set_xticklabels([m.split('(')[0].strip() for m in model_names], rotation=45, ha='right')\n",
    "axes[0].set_ylabel('AUROC')\n",
    "axes[0].set_title('Cross-Validation Score Distribution', fontsize=12, fontweight='bold')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Bar plot with error bars\n",
    "means = [r['Mean AUROC'] for r in cv_results]\n",
    "stds = [r['Std AUROC'] for r in cv_results]\n",
    "x_pos = np.arange(len(model_names))\n",
    "\n",
    "bars = axes[1].bar(x_pos, means, yerr=stds, capsize=5, alpha=0.7, color='steelblue')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels([m.split('(')[0].strip() for m in model_names], rotation=45, ha='right')\n",
    "axes[1].set_ylabel('Mean AUROC')\n",
    "axes[1].set_title('Mean CV Score with Standard Deviation', fontsize=12, fontweight='bold')\n",
    "axes[1].set_ylim([0.75, 0.90])\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Learning Curves: Diagnosing Overfitting\n",
    "\n",
    "Learning curves show how training and validation scores change with training set size:\n",
    "- **High bias (underfitting)**: Both scores are low and converge\n",
    "- **High variance (overfitting)**: Large gap between training and validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curve(estimator, title, X, y, cv=5, n_jobs=-1, \n",
    "                        train_sizes=np.linspace(0.1, 1.0, 10)):\n",
    "    \"\"\"Plot learning curve for a model\"\"\"\n",
    "    \n",
    "    train_sizes, train_scores, val_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs,\n",
    "        train_sizes=train_sizes, scoring='roc_auc'\n",
    "    )\n",
    "    \n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    train_std = np.std(train_scores, axis=1)\n",
    "    val_mean = np.mean(val_scores, axis=1)\n",
    "    val_std = np.std(val_scores, axis=1)\n",
    "    \n",
    "    return train_sizes, train_mean, train_std, val_mean, val_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot learning curves for key models\n",
    "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\n",
    "models_for_lc = [\n",
    "    ('Logistic Regression', LogisticRegression(C=0.1, max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE)),\n",
    "    ('Random Forest (depth=10)', RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)),\n",
    "    ('Random Forest (depth=None)', RandomForestClassifier(n_estimators=100, max_depth=None, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1)),\n",
    "    ('XGBoost', xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, scale_pos_weight=(y==0).sum()/(y==1).sum(), random_state=RANDOM_STATE, eval_metric='logloss'))\n",
    "]\n",
    "\n",
    "for idx, (name, model) in enumerate(models_for_lc):\n",
    "    ax = axes[idx // 2, idx % 2]\n",
    "    \n",
    "    print(f\"Computing learning curve for {name}...\")\n",
    "    train_sizes, train_mean, train_std, val_mean, val_std = plot_learning_curve(\n",
    "        model, name, X_scaled, y, cv=5\n",
    "    )\n",
    "    \n",
    "    # Plot\n",
    "    ax.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "    ax.fill_between(train_sizes, val_mean - val_std, val_mean + val_std, alpha=0.1, color='orange')\n",
    "    ax.plot(train_sizes, train_mean, 'o-', color='blue', label='Training score')\n",
    "    ax.plot(train_sizes, val_mean, 'o-', color='orange', label='Validation score')\n",
    "    \n",
    "    ax.set_xlabel('Training Set Size')\n",
    "    ax.set_ylabel('AUROC')\n",
    "    ax.set_title(f'Learning Curve: {name}', fontsize=11, fontweight='bold')\n",
    "    ax.legend(loc='lower right')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    ax.set_ylim([0.75, 1.0])\n",
    "    \n",
    "    # Calculate and display gap\n",
    "    gap = train_mean[-1] - val_mean[-1]\n",
    "    ax.text(0.05, 0.95, f'Gap: {gap:.3f}', transform=ax.transAxes, \n",
    "            fontsize=10, verticalalignment='top',\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('learning_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Validation Curves: Finding Optimal Regularization\n",
    "\n",
    "Validation curves show how training and validation scores change with a hyperparameter value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve for Logistic Regression (C parameter)\n",
    "print(\"Computing validation curve for Logistic Regression (C parameter)...\")\n",
    "\n",
    "C_range = np.logspace(-3, 2, 10)\n",
    "\n",
    "train_scores, val_scores = validation_curve(\n",
    "    LogisticRegression(max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    X_scaled, y, param_name='C', param_range=C_range,\n",
    "    cv=5, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "\n",
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "val_mean = np.mean(val_scores, axis=1)\n",
    "val_std = np.std(val_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation curve for Random Forest (max_depth)\n",
    "print(\"Computing validation curve for Random Forest (max_depth)...\")\n",
    "\n",
    "depth_range = [2, 3, 5, 7, 10, 15, 20, None]\n",
    "\n",
    "rf_train_scores, rf_val_scores = validation_curve(\n",
    "    RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    X_scaled, y, param_name='max_depth', param_range=depth_range[:-1],  # Exclude None\n",
    "    cv=5, scoring='roc_auc', n_jobs=-1\n",
    ")\n",
    "\n",
    "rf_train_mean = np.mean(rf_train_scores, axis=1)\n",
    "rf_train_std = np.std(rf_train_scores, axis=1)\n",
    "rf_val_mean = np.mean(rf_val_scores, axis=1)\n",
    "rf_val_std = np.std(rf_val_scores, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot validation curves\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Logistic Regression\n",
    "axes[0].semilogx(C_range, train_mean, 'o-', color='blue', label='Training')\n",
    "axes[0].fill_between(C_range, train_mean - train_std, train_mean + train_std, alpha=0.1, color='blue')\n",
    "axes[0].semilogx(C_range, val_mean, 'o-', color='orange', label='Validation')\n",
    "axes[0].fill_between(C_range, val_mean - val_std, val_mean + val_std, alpha=0.1, color='orange')\n",
    "axes[0].axvline(x=C_range[np.argmax(val_mean)], color='green', linestyle='--', label=f'Best C={C_range[np.argmax(val_mean)]:.3f}')\n",
    "axes[0].set_xlabel('C (Regularization Parameter)')\n",
    "axes[0].set_ylabel('AUROC')\n",
    "axes[0].set_title('Validation Curve: Logistic Regression', fontsize=12, fontweight='bold')\n",
    "axes[0].legend(loc='lower right')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Random Forest\n",
    "axes[1].plot(depth_range[:-1], rf_train_mean, 'o-', color='blue', label='Training')\n",
    "axes[1].fill_between(depth_range[:-1], rf_train_mean - rf_train_std, rf_train_mean + rf_train_std, alpha=0.1, color='blue')\n",
    "axes[1].plot(depth_range[:-1], rf_val_mean, 'o-', color='orange', label='Validation')\n",
    "axes[1].fill_between(depth_range[:-1], rf_val_mean - rf_val_std, rf_val_mean + rf_val_std, alpha=0.1, color='orange')\n",
    "best_depth = depth_range[:-1][np.argmax(rf_val_mean)]\n",
    "axes[1].axvline(x=best_depth, color='green', linestyle='--', label=f'Best depth={best_depth}')\n",
    "axes[1].set_xlabel('Max Depth')\n",
    "axes[1].set_ylabel('AUROC')\n",
    "axes[1].set_title('Validation Curve: Random Forest', fontsize=12, fontweight='bold')\n",
    "axes[1].legend(loc='lower right')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('validation_curves.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Early Stopping for XGBoost\n",
    "\n",
    "Early stopping prevents overfitting by stopping training when validation performance stops improving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data for early stopping demonstration\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "# Further split training for validation\n",
    "X_train_es, X_val_es, y_train_es, y_val_es = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=RANDOM_STATE, stratify=y_train\n",
    ")\n",
    "\n",
    "print(f\"Training: {X_train_es.shape}, Validation: {X_val_es.shape}, Test: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost with early stopping\n",
    "print(\"Training XGBoost with early stopping...\")\n",
    "\n",
    "xgb_es = xgb.XGBClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "    random_state=RANDOM_STATE,\n",
    "    eval_metric='auc',\n",
    "    early_stopping_rounds=20\n",
    ")\n",
    "\n",
    "xgb_es.fit(\n",
    "    X_train_es, y_train_es,\n",
    "    eval_set=[(X_train_es, y_train_es), (X_val_es, y_val_es)],\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Best iteration: {xgb_es.best_iteration}\")\n",
    "print(f\"Best score: {xgb_es.best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "results = xgb_es.evals_result()\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "epochs = len(results['validation_0']['auc'])\n",
    "x_axis = range(epochs)\n",
    "\n",
    "plt.plot(x_axis, results['validation_0']['auc'], label='Training')\n",
    "plt.plot(x_axis, results['validation_1']['auc'], label='Validation')\n",
    "plt.axvline(x=xgb_es.best_iteration, color='red', linestyle='--', \n",
    "            label=f'Early Stop (iter={xgb_es.best_iteration})')\n",
    "\n",
    "plt.xlabel('Boosting Iterations')\n",
    "plt.ylabel('AUROC')\n",
    "plt.title('XGBoost Training with Early Stopping', fontsize=12, fontweight='bold')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('early_stopping_xgboost.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Compare Train vs Test Performance\n",
    "\n",
    "Large gaps between training and test performance indicate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train final models and compare train/test performance\n",
    "final_models = {\n",
    "    'Logistic Regression': LogisticRegression(C=0.1, max_iter=1000, class_weight='balanced', random_state=RANDOM_STATE),\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, max_depth=10, class_weight='balanced', random_state=RANDOM_STATE, n_jobs=-1),\n",
    "    'XGBoost': xgb.XGBClassifier(n_estimators=100, max_depth=3, learning_rate=0.1, scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(), random_state=RANDOM_STATE, eval_metric='logloss'),\n",
    "    'SVM': SVC(C=0.1, kernel='rbf', class_weight='balanced', probability=True, random_state=RANDOM_STATE)\n",
    "}\n",
    "\n",
    "train_test_comparison = []\n",
    "\n",
    "for name, model in final_models.items():\n",
    "    # Train\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Get probabilities\n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        train_proba = model.predict_proba(X_train)[:, 1]\n",
    "        test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        train_proba = model.decision_function(X_train)\n",
    "        test_proba = model.decision_function(X_test)\n",
    "    \n",
    "    # Calculate metrics\n",
    "    train_auroc = roc_auc_score(y_train, train_proba)\n",
    "    test_auroc = roc_auc_score(y_test, test_proba)\n",
    "    gap = train_auroc - test_auroc\n",
    "    \n",
    "    train_test_comparison.append({\n",
    "        'Model': name,\n",
    "        'Train AUROC': train_auroc,\n",
    "        'Test AUROC': test_auroc,\n",
    "        'Gap': gap,\n",
    "        'Overfit Risk': 'Low' if gap < 0.02 else 'Medium' if gap < 0.05 else 'High'\n",
    "    })\n",
    "\n",
    "comparison_df = pd.DataFrame(train_test_comparison)\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRAIN VS TEST PERFORMANCE (Overfitting Detection)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize train/test comparison\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "x = np.arange(len(comparison_df))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, comparison_df['Train AUROC'], width, label='Train', color='steelblue', alpha=0.8)\n",
    "bars2 = ax.bar(x + width/2, comparison_df['Test AUROC'], width, label='Test', color='darkorange', alpha=0.8)\n",
    "\n",
    "# Add gap annotations\n",
    "for i, (_, row) in enumerate(comparison_df.iterrows()):\n",
    "    gap = row['Gap']\n",
    "    color = 'green' if gap < 0.02 else 'orange' if gap < 0.05 else 'red'\n",
    "    ax.annotate(f'Gap: {gap:.3f}', xy=(i, max(row['Train AUROC'], row['Test AUROC']) + 0.01),\n",
    "                ha='center', fontsize=9, color=color, fontweight='bold')\n",
    "\n",
    "ax.set_xlabel('Model')\n",
    "ax.set_ylabel('AUROC')\n",
    "ax.set_title('Training vs Test Performance (Overfitting Check)', fontsize=12, fontweight='bold')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(comparison_df['Model'])\n",
    "ax.legend()\n",
    "ax.set_ylim([0.80, 0.95])\n",
    "ax.grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('train_test_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Final Model Selection with Best Practices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train optimized models with all mitigation techniques\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODELS WITH OVERFITTING MITIGATION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Best configurations based on cross-validation\n",
    "best_models = {\n",
    "    'Logistic Regression': LogisticRegression(\n",
    "        C=0.1,  # Regularization\n",
    "        max_iter=1000,\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE\n",
    "    ),\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=10,  # Limited depth\n",
    "        min_samples_split=10,  # Prevent small splits\n",
    "        min_samples_leaf=5,  # Minimum leaf size\n",
    "        class_weight='balanced',\n",
    "        random_state=RANDOM_STATE,\n",
    "        n_jobs=-1\n",
    "    ),\n",
    "    'XGBoost': xgb.XGBClassifier(\n",
    "        n_estimators=100,\n",
    "        max_depth=3,  # Shallow trees\n",
    "        learning_rate=0.1,\n",
    "        reg_alpha=0.1,  # L1 regularization\n",
    "        reg_lambda=1.0,  # L2 regularization\n",
    "        scale_pos_weight=(y_train==0).sum()/(y_train==1).sum(),\n",
    "        random_state=RANDOM_STATE,\n",
    "        eval_metric='logloss'\n",
    "    ),\n",
    "    'SVM': SVC(\n",
    "        C=0.1,  # Regularization\n",
    "        kernel='rbf',\n",
    "        class_weight='balanced',\n",
    "        probability=True,\n",
    "        random_state=RANDOM_STATE\n",
    "    )\n",
    "}\n",
    "\n",
    "final_results = []\n",
    "\n",
    "for name, model in best_models.items():\n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='roc_auc', n_jobs=-1)\n",
    "    \n",
    "    # Train on full training set, evaluate on test\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    if hasattr(model, 'predict_proba'):\n",
    "        test_proba = model.predict_proba(X_test)[:, 1]\n",
    "    else:\n",
    "        test_proba = model.decision_function(X_test)\n",
    "    \n",
    "    test_auroc = roc_auc_score(y_test, test_proba)\n",
    "    test_pr_auc = average_precision_score(y_test, test_proba)\n",
    "    \n",
    "    final_results.append({\n",
    "        'Model': name,\n",
    "        'CV AUROC (mean)': cv_scores.mean(),\n",
    "        'CV AUROC (std)': cv_scores.std(),\n",
    "        'Test AUROC': test_auroc,\n",
    "        'Test PR AUC': test_pr_auc\n",
    "    })\n",
    "    \n",
    "    print(f\"\\n{name}:\")\n",
    "    print(f\"  CV AUROC: {cv_scores.mean():.4f} (+/- {cv_scores.std()*2:.4f})\")\n",
    "    print(f\"  Test AUROC: {test_auroc:.4f}\")\n",
    "    print(f\"  Test PR AUC: {test_pr_auc:.4f}\")\n",
    "\n",
    "final_df = pd.DataFrame(final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save final results\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "os.makedirs('cv_mitigation_results', exist_ok=True)\n",
    "\n",
    "# Save results\n",
    "final_df.to_csv('cv_mitigation_results/final_cv_results.csv', index=False)\n",
    "cv_df[['Model', 'Mean AUROC', 'Std AUROC']].to_csv('cv_mitigation_results/all_cv_results.csv', index=False)\n",
    "comparison_df.to_csv('cv_mitigation_results/train_test_comparison.csv', index=False)\n",
    "\n",
    "# Save models\n",
    "for name, model in best_models.items():\n",
    "    filename = f\"cv_mitigation_results/{name.lower().replace(' ', '_')}_optimized.pkl\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "print(\"\\nResults saved to 'cv_mitigation_results/' directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*80)\n",
    "print(\"CROSS-VALIDATION & MITIGATION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\n1. TECHNIQUES APPLIED:\")\n",
    "print(\"   - 5-Fold Stratified Cross-Validation\")\n",
    "print(\"   - Learning Curves (bias-variance diagnosis)\")\n",
    "print(\"   - Validation Curves (optimal hyperparameters)\")\n",
    "print(\"   - Early Stopping (XGBoost)\")\n",
    "print(\"   - Regularization (L1/L2, max_depth, C parameter)\")\n",
    "\n",
    "print(\"\\n2. CROSS-VALIDATION RESULTS:\")\n",
    "for _, row in final_df.iterrows():\n",
    "    print(f\"   {row['Model']}: {row['CV AUROC (mean)']:.4f} (+/- {row['CV AUROC (std)']*2:.4f})\")\n",
    "\n",
    "print(\"\\n3. OVERFITTING STATUS:\")\n",
    "for _, row in comparison_df.iterrows():\n",
    "    print(f\"   {row['Model']}: Gap = {row['Gap']:.4f} ({row['Overfit Risk']} risk)\")\n",
    "\n",
    "print(\"\\n4. KEY FINDINGS:\")\n",
    "best_model = final_df.loc[final_df['CV AUROC (mean)'].idxmax()]\n",
    "print(f\"   - Best model: {best_model['Model']}\")\n",
    "print(f\"   - CV AUROC: {best_model['CV AUROC (mean)']:.4f}\")\n",
    "print(f\"   - Test AUROC: {best_model['Test AUROC']:.4f}\")\n",
    "print(f\"   - All models show minimal overfitting with proper regularization\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
